---
sidebar_label: Open WebUI
description: Open WebUI mit mittwald AI Hosting für erweiterte KI-Anwendungsfälle verwenden
title: Open WebUI mit mittwald AI Hosting
---

Open WebUI lässt sich als ChatGPT-ähnliches Interface mit mittwald AI Hosting betreiben. Sofern dein Projekt in einem Container-fähigen Produkt angesiedelt ist, kann es beim Anlegen des API-Keys automatisch mit installiert und konfiguriert werden. Andernfalls kannst du Open WebUI nach unserer [Deployment-Anleitung](/docs/v2/guides/apps/openwebui) im Container-Hosting aufsetzen.

## Verbindung mit mittwald AI Hosting {#connecting}

Wenn du das Managed Deployment, wird dein Open WebUI bereits mit einer Verbindung zum mittwald AI-Hosting vorkonfiguriert. Ansonsten gibt es zwei Möglichkeiten, Open WebUI mit mittwald AI Hosting zu verbinden:

### Verwendung von Umgebungsvariablen (Empfohlen) {#env-variables}

Die empfohlene Methode ist die Konfiguration der Verbindung während des Container-Deployments mittels Umgebungsvariablen. Siehe die [Deployment-Anleitung](/docs/v2/guides/apps/openwebui#verbindung-mit-mittwald-ai-hosting) für detaillierte Anweisungen.

### Verwendung des Admin Panels {#admin-panel}

Falls nicht automatisch verbunden, kannst du die Verbindung im Admin Panel einrichten:

1. Gehe zu **„Settings"** und wähle **„Connections"**
2. Im Bereich **„OpenAI API"** füge eine weitere Verbindung hinzu
3. Gib die Basis-URL ein: `https://llm.aihosting.mittwald.de/v1`
4. Gib deinen API-Key ein

Open WebUI wird automatisch alle verfügbaren Modelle erkennen.

## Optimierung der Modell-Parameter {#model-parameters}

Für optimale Ergebnisse kann es erforderlich sein, die Standard-Parameter von Open WebUI für jedes Modell anzupassen.

1. Navigiere zum Bereich **„Models"** in Open WebUI
2. Wähle das Modell aus, das du konfigurieren möchtest
3. Unter **„Advanced Params"** setze die empfohlenen Parameter, die im [Modell-Bereich](/docs/v2/platform/aihosting/models/) dokumentiert sind, wie z.B. `top_p`, `top_k` und `temperature`

:::note
Wir empfehlen, die Embedding-Modelle in der Modellauswahl auszublenden, da sie automatisch von Open WebUI erkannt werden, aber nicht in einem Chat verwendet werden können.
:::

## Verwendung von Retrieval-Augmented Generation (RAG) {#rag}

Open WebUI bietet die Funktion an, Wissen in Form von Dokumenten zu hinterlegen, auf die zugegriffen werden kann. Hierbei handelt es sich um sog. Retrieval-Augmented Generation (RAG).

### Hochladen von Dokumenten {#rag-documents}

1. Navigiere in der linken Menüleiste zu **„Workspace"**
2. Wähle den Reiter **„Knowledge"**
3. Lade Dokumente hoch, die du verfügbar machen möchtest
4. In deinen Chats kannst du mit einem Hashtag auf diese Dokumente zugreifen

### Konfiguration eines Embedding-Modells {#rag-embedding}

Für performantere Verarbeitung kann ein Embedding-Modell genutzt werden:

1. Im Admin Panel unter **„Settings"** findet sich der Menüpunkt **„Documents"**
2. Im Bereich **„Embedding"** wähle zunächst im Dropdown-Menü **„OpenAI"** für die Embedding Model Engine aus
3. Gib den Endpunkt ein: `https://llm.aihosting.mittwald.de/v1`
4. Gib deinen generierten API-Key ein
5. Wähle unter **„Embedding Model"** ein von uns angebotenes [Embedding-Modell](/docs/v2/platform/aihosting/models/) aus (wie z.B. Qwen3-Embedding-8B)
6. Passe im Bereich **„Retrieval"** die Parameter **„Top K"** und **„RAG Template"** für optimale Ergebnisse an

## Konfiguration von Speech-to-Text {#speech-to-text}

Whisper-Large-V3-Turbo kann in Open WebUI für Speech-to-Text (STT) Funktionalität konfiguriert werden. Dieses Modell unterstützt über 99 Sprachen und ist für Audio-Transkription über unsere gehostete API optimiert.

### Konfiguration im Admin Panel {#stt-setup}

Im Admin Panel unter **„Settings"** > **„Audio"** sind folgende Einstellungen vorzunehmen:

- **Engine**: Wähle „OpenAI"
- **API Base URL**: Gib `https://llm.aihosting.mittwald.de/v1` ein
- **API Key**: Gib deinen API-Key ein
- **STT Model**: Gib den Modellnamen `whisper-large-v3-turbo` ein

### Whisper aus Chat-Modellen ausblenden {#stt-hide}

Whisper wird nach der Verbindung in der Modellliste erscheinen, sollte aber aus der Chat-Modell-Auswahl ausgeblendet werden, da es für Audio-Transkription entwickelt wurde, nicht für konversationelle KI:

1. Navigiere zu **„Workspace"** > **„Models"**
2. Wähle **Whisper-Large-V3-Turbo** aus
3. Wähle **„Hide"**, um zu verhindern, dass es als Chat-Option erscheint

### Benutzereinstellungen {#stt-user-settings}

Du kannst weiter spezifizieren, wie Open WebUI mit dem Whisper-Modell interagiert in den Benutzereinstellungen (nicht im Administrator-Panel) unter **„Audio"**:

- **Language**: Setze den Sprachcode explizit (z.B. „de" für Deutsch, „en" für Englisch)
- **Directly Send Speech**: Aktiviere, um Transkriptionen direkt ohne Bestätigung zu senden

### Empfohlene Parameter {#stt-parameters}

Für optimale Transkriptionsqualität konfiguriere diese Parameter im Admin Panel oder in den Chat-Einstellungen:

- **Additional Parameters**: Setze `temperature=1.0`, `top_p=1.0`

### Testen von Speech-to-Text {#stt-testing}

Um die Speech-to-Text-Funktionalität zu testen:

1. Klicke auf das Mikrofon-Symbol in einer Chat-Oberfläche
2. Sprich in der konfigurierten Sprache
3. Die Transkription verwendet unseren `/v1/audio/transcriptions`-Endpunkt mit Unterstützung für MP3-, OGG-, WAV- und FLAC-Formate (maximale Dateigröße 25 MB)

:::note
Setze den Sprachparameter immer explizit für beste Genauigkeit, insbesondere für nicht-deutsche Audioeingaben.
:::

Du kannst Whisper nun in jedem Chat verwenden! Chatte mit deinem Lieblings-LLM, indem du deine Frage diktierst und absendest.
