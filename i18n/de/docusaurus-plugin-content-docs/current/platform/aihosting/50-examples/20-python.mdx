---
sidebar_label: Python
description: Programmatische Beispiele in Python, wie das AI-Hosting genutzt werden kann
title: Python-Beispiele
---

Die Nutzung der Modelle innerhalb von Programmiersprachen kann komfortabel über bestehende Libraries stattfinden, welche die OpenAI-API unterstützen. Somit kann mittwalds AI-Hosting in vielen Fällen als Drop-In-Replacement genutzt werden.

Für die folgenden Beispiele müssen zunächst über einen Python-Paketmanager die Libraries installiert werden und der im mStudio generierte API-Key in einer `.env`-Datei hinterlegt werden:

```sh
pip install python-dotenv openai langchain-openai
echo 'OPENAI_API_KEY="sk-…"' > .env
```

Anschließend kann über das `OpenAI`-Paket ein Modell angesprochen werden:

```python
from openai import OpenAI
from dotenv import load_dotenv

# Load .env file
load_dotenv()

# Initialize client with custom host and key from environment
client = OpenAI(
    base_url="https://llm.aihosting.mittwald.de/v1"
)

# Make a simple call
response = client.chat.completions.create(
    model="Ministral-3-14B-Instruct-2512",
    temperature = 0.15,
    messages=[
        {"role": "user", "content": "Moin und hallo!"}
    ]
)

print(response.choices[0].message.content)
```

Alternativ kann auch `langchain` verwendet werden:

```python
from dotenv import load_dotenv
from langchain_openai import ChatOpenAI
from langchain_core.messages import HumanMessage

# Load .env file
load_dotenv()

# Initialize client with custom host and key from environment
chat = ChatOpenAI(
    model="Ministral-3-14B-Instruct-2512",
    base_url="https://llm.aihosting.mittwald.de/v1",
    temperature = 0.15
)

# Get response
response = chat.invoke([
    HumanMessage(content="Moin and hello!")
])

print(response.content)
```

## Vision (Bild + Text)

```python
from openai import OpenAI
client = OpenAI(base_url="https://llm.aihosting.mittwald.de/v1")

resp = client.chat.completions.create(
    model="Ministral-3-14B-Instruct-2512",
    messages=[{
        "role": "user",
        "content": [
            {"type": "text", "text": "Beschreibe dieses Bild kurz."},
            {"type": "image_url", "image_url": {"url": "https://example.com/sample.jpg"}}
        ]
    }],
    temperature=0.1
)
print(resp.choices[0].message.content)
```

Hinweise: bis zu 4 Bilder pro Anfrage empfohlen; quadratische Seitenverhältnisse sind robuster.

## Tool-Calling (Function Calling)

```python
from openai import OpenAI
client = OpenAI(base_url="https://llm.aihosting.mittwald.de/v1")

tools = [
  {
    "type": "function",
    "function": {
      "name": "get_weather",
      "description": "Aktuelles Wetter abrufen",
      "parameters": {
        "type": "object",
        "properties": {"city": {"type": "string"}},
        "required": ["city"]
      }
    }
  }
]

resp = client.chat.completions.create(
    model="Devstral-Small-2-24B-Instruct-2512",
    messages=[{"role": "user", "content": "Wie ist das Wetter in Berlin?"}],
    tools=tools,
    tool_choice="auto"
)

# Prüfen, ob das Modell ein Tool aufgerufen hat
if resp.choices[0].message.tool_calls:
    call = resp.choices[0].message.tool_calls[0]
    print(f"Funktion: {call.function.name}")
    print(f"Argumente: {call.function.arguments}")
```

## Streaming-Antworten

```python
from openai import OpenAI
client = OpenAI(base_url="https://llm.aihosting.mittwald.de/v1")

stream = client.chat.completions.create(
    model="Devstral-Small-2-24B-Instruct-2512",
    messages=[{"role": "user", "content": "Schreibe ein kurzes Gedicht über das Programmieren"}],
    stream=True
)

for chunk in stream:
    if chunk.choices[0].delta.content:
        print(chunk.choices[0].delta.content, end="", flush=True)
```
